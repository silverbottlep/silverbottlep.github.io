<!DOCTYPE html>
<html lang="en">
<head>
  <title>Eunbyung Park</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="css/main.css">
  <link rel="stylesheet" href="css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Nunito">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
</head>

<body>
<nav class="navbar navbar-inverse">
  <div class="container-fluid">
    <div class="navbar-header">
      <a class="navbar-brand" href="index.html">Eunbyung Park</a>
    </div>
    <ul class="nav navbar-nav">
      <li><a href="index.html">Home</a></li>
      <li><a href="pair.html">Team</a></li>
      <li class="active"><a href="publication.html">Publications</a></li>
      <li><a href="teaching.html">Teaching</a></li>
    </ul>
  </div>
</nav>

  <div id="main">
        <h3>Preprints </h3>
                <li class="list-group-item">
                <p class="paper"><b>Deblurring 3D Gaussian Splatting</b></p> 
                <p class="paper">Byeonghyeon Lee*, Howoong Lee*, Xiangyu Sun, Usman Ali, Eunbyung Park</p>
                <p class="paper">arXiv:2401.00834</p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2401.00834">Paper</a>] [<a target="_blank" href="https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/">Project Page</a>] [<a target="_blank" href="https://github.com/benhenryL/Deblurring-3D-Gaussian-Splatting">Code coming soon!</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Compact 3D Gaussian Representation for Radiance Field</b></p> 
                <p class="paper">Joo Chan Lee, Daniel Rho, Xiangyu Sun, Jong Hwan Ko, Eunbyung Park</p>
                <p class="paper">arXiv:2311.13681</p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2311.13681">Paper</a>] [<a target="_blank" href="https://maincold2.github.io/c3dgs/">Project Page</a>] [<a target="_blank" href="https://github.com/maincold2/Compact-3DGS">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Hydra: Multi-head Low-rank Adaptation for Parameter Efficient Fine-tuning</b></p> 
                <p class="paper">Sanghyeon Kim*, Hyunmo Yang*, Younghyun Kim*, Youngjoon Hong, Eunbyung Park</p>
                <p class="paper">arXiv:2309.06922</p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2309.06922">Paper</a>] [<a target="_blank" href="https://github.com/extremebird/Hydra">Code</a>]</p>
                </li>
        <h3>Publications</h3>
                <li class="list-group-item">
                <p class="paper"><b>Coordinate-Aware Modulation for Neural Fields</b></p> 
                <p class="paper">Joo Chan Lee, Daniel Rho, Seungtae Nam, Jong Hwan Ko, Eunbyung Park</p>
                <p class="paper">International Conference on Learning Representations, <b>ICLR 2024</b>, <b style="color:#C34A2C">Spotlight!</b> (acceptance rate = 6.2%) </p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2311.14993">Paper</a>] [<a target="_blank" href="https://maincold2.github.io/cam/">Project Page</a>] [<a target="_blank" href="https://github.com/maincold2/cam">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Sharp-NeRF: Grid-based Fast Deblurring Neural Radiance Field using Sharpness Prior</b></p> 
                <p class="paper">Byeonghyeon Lee*, Howoong Lee*, Usman Ali, Eunbyung Park</p>
                <p class="paper">The IEEE/CVF Winter Conference on Applications of Computer Vision, <b>WACV 2024</b></p>
                <p class="paper">[<a target="_blank" href="https://openaccess.thecvf.com/content/WACV2024/html/Lee_Sharp-NeRF_Grid-Based_Fast_Deblurring_Neural_Radiance_Fields_Using_Sharpness_Prior_WACV_2024_paper.html">Paper</a>] [<a target="_blank" href="https://benhenryl.github.io/SharpNeRF/">Project Page</a>] [<a target="_blank" href="https://github.com/benhenryL/SharpNeRF">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Mip-Grid: Anti-aliased Grid Representations for Neural Radiance Fields</b></p> 
                <p class="paper">Seungtae Nam, Daniel Rho, Jong Hwan Ko, Eunbyung Park</p>
                <p class="paper">Neural Information Processing Systems, <b>NeurIPS 2023</b></p>
                <p class="paper">[<a target="_blank" href="https://openreview.net/pdf?id=BW6nZf7TnK">Paper</a>] [<a target="_blank" href="https://stnamjef.github.io/mipgrid.github.io/">Project Page</a>] [<a target="_blank" href="https://github.com/stnamjef/MipGrid">Code</a>]</p>
                </li> 
                <li class="list-group-item">
                <p class="paper"><b>Separable Physics-Informed Neural Networks</b></p> 
                <p class="paper">Junwoo Cho*, Seungtae Nam*, Hyunmo Yang, Seok-Bae Yun, Youngjoon Hong, Eunbyung Park</p>
                <p class="paper">Neural Information Processing Systems, <b>NeurIPS 2023</b>, <b style="color:#C34A2C">Spotlight!</b> (acceptance rate = 3.06%) </p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2306.15969">Paper</a>] [<a target="_blank" href="https://jwcho5576.github.io/spinn.github.io/">Project Page</a>] [<a target="_blank" href="https://github.com/stnamjef/SPINN">Code</a>] [<a target="_blank" href="https://arxiv.org/abs/2211.08761">NeurIPS DLDE 2022 Workshop Paper</a>] [<a target="_blank" href="https://youtu.be/S-b26O2OWhI?t=4759">Recorded talk</a>] </p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>FFNeRV: Flow-Guided Frame-Wise Neural Representations for Videos</b></p> 
                <p class="paper">Joo Chan Lee, Daniel Rho, Jong Hwan Ko, Eunbyung Park</p>
                <p class="paper">The ACM International Conference on Multimedia, <b>ACM MM 2023</b> </p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2212.12294">Paper</a>] [<a target="_blank" href="https://maincold2.github.io/ffnerv/">Project Page</a>] [<a target="_blank" href="https://github.com/maincold2/FFNeRV">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Masked Wavelet Representation for Compact Neural Radiance Fields</b></p> 
                <p class="paper">Daniel Rho*, Byeonghyeon Lee*, Seungtae Nam, Joo Chan Lee, Jong Hwan Ko, Eunbyung Park</p>
                <p class="paper">The IEEE/CVF Conference on Computer Vision and Pattern Recognition, <b>CVPR 2023</b></p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2212.09069">Paper</a>] [<a target="_blank" href="https://daniel03c1.github.io/masked_wavelet_nerf/">Project Page</a>] [<a target="_blank" href="https://github.com/daniel03c1/masked_wavelet_nerf">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>SMPConv: Self-Moving Point Representations for Continuous Convolution</b></p> 
                <p class="paper">Sanghyeon Kim, Eunbyung Park</p>
                <p class="paper">The IEEE/CVF Conference on Computer Vision and Pattern Recognition, <b>CVPR 2023</b></p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2304.02330">Paper</a>] [<a target="_blank" href="https://github.com/sangnekim/SMPConv">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>PIXEL: Physics-Informed Cell Representations for Fast and Accurate PDE Solvers</b></p> 
                <p class="paper">Namgyu Kang, Byeonghyeon Lee, Youngjoon Hong, Seok-Bae Yun, Eunbyung Park</p>
                <p class="paper">The 37th AAAI Conference on Artificial Intelligence, <b>AAAI 2023</b></p>
                <p class="paper"><a target="_blank" href="https://dlde-2022.github.io/">The Symbiosis of Deep Learning and Differential Equations</a>, <b>NeurIPS 2022 Workshop</b>, <b style="color:#C34A2C">Spotlight!</b></p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2207.12800">Paper</a>] [<a target="_blank" href="https://namgyukang.github.io/PIXEL/">Project Page</a>] [<a target="_blank" href="https://github.com/NamGyuKang/PIXEL">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Streamable Neural Fields</b></p>
                <p class="paper">Junwoo Cho*, Seungtae Nam*, Daniel Rho, Jong Hwan Ko, Eunbyung Park</p>
                <p class="paper">European Conference on Computer Vision, <b>ECCV 2022</b></p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2207.09663">Paper</a>] [<a target="_blank" href="https://github.com/jwcho5576/streamable_nf">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Neural Residual Flow Fields for Efficient Video Representations</b></p>
                <p class="paper">Daniel Rho, Junwoo Cho, Jong Hwan Ko, Eunbyung Park</p>
                <p class="paper">Asian Conference on Computer Vision, <b>ACCV 2022</b></p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/2201.04329">Paper</a>] [<a target="_blank" href="https://github.com/daniel03c1/eff_video_representation">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Rotationally-Temporally Consistent Novel View Synthesis of Human Performance Video</b></p>
                <p class="paper">YoungJoong Kwon, Stefano Petrangeli, Dahun Kim, Haoliang Wang, Eunbyung Park, Vishy Swaminathan, Henry Fuchs</p>
                <p class="paper">European Conference on Computer Vision, <b>ECCV 2020</b></p>
                <p class="paper">[<a target="_blank" href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490375.pdf">Paper</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Unsupervised Doodling and Painting with Improved SPIRAL</b></p>
                <p class="paper">John F. J. Mellor, Eunbyung Park, Yaroslav Ganin, Igor Babuschkin, Tejas Kulkarni, Dan Rosenbaum, Andy Ballard, Theophane Weber, Oriol Vinyals, S. M. Ali Eslami</p>
                <p class="paper">Machine Learning for Creativity and Design, <b>NeurIPS 2019 Workshop</b></p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/1910.01007">Paper</a>] [<a target="_blank" href="https://learning-to-paint.github.io/">Animated Paper</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Meta-Curvature</b></p>
                <p class="paper">Eunbyung Park, Junier B. Oliva</p>
                <p class="paper">Neural Information Processing Systems, <b>NeurIPS 2019</b></p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/1902.03356">Paper</a>] [<a target="_blank" href="https://github.com/silverbottlep/meta_curvature">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Three years of Low-Power Image Recognition Challenge</b></p>
                <p class="paper">Kent Gauen, Ryan Dailey, Yung-Hsiang Lu, Eunbyung Park, Wei Liu, Alexander C Berg, Yiran Chen </p>
                <p class="paper">Design, Automation and Test in Europe Conference, <b>DATE 2018 Exhibition</b><br>
                <p class="paper">[<a target="_blank" href="https://ieeexplore.ieee.org/document/8342099">Paper</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Meta-Tracker: Fast and Robust Online Adaptation for Visual Object Trackers</b></p>
                <p class="paper">Eunbyung Park, Alexander C. Berg</p>
                <p class="paper">European Conference on Computer Vision, <b>ECCV 2018</b></p>
                <p class="paper">[<a target="_blank" href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Eunbyung_Park_Meta-Tracker_Fast_and_ECCV_2018_paper.pdf">Paper</a>] [<a target="_blank" href="https://github.com/silverbottlep/meta_trackers">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>A Dataset for Developing and Benchmarking Active Vision</b></p>
                <p class="paper">Phil Ammirato, Patrick Poirson, Eunbyung Park, Jana Kosecka, Alexander C. Berg</p>
                <p class="paper">International Conference on Robotics and Automation, <b>ICRA 2017</b></p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/1702.08272">Paper</a>] [<a target="_blank" href="http://www.cs.unc.edu/~ammirato/active_vision_dataset_website/index.html">Project Page</a>]</p> 
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Transformation-Grounded Image Generation Network for Novel 3D View Synthesis</b></p>
                <p class="paper">Eunbyung Park, Jimei Yang, Ersin Yumer, Duygu Ceylan, Alexander C. Berg</p>
                <p class="paper">The IEEE/CVF Conference on Computer Vision and Pattern Recognition, <b>CVPR 2017</b></p>
                <p class="paper">[<a target="_blank" href="https://arxiv.org/abs/1703.02921">Paper</a>] [<a target="_blank" href="http://www.cs.unc.edu/~eunbyung/tvsn/">Project Page</a>] [<a target="_blank" href="https://github.com/silverbottlep/tvsn">Code</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>An Evaluation of the NVIDIA TX1 for Supporting Real-Time Computer Vision Workloads</b></p>
                <p class="paper">Nathan Otterness, Ming Yang, Sarah Rust, Eunbyung Park, James H. Anderson, F. Donelson Smith, Alexander C. Berg, Shige Wang</p>
                <p class="paper">Real-Time and Embedded Technology and Applications Symposium, <b>RTAS 2017</b></p>
                <p class="paper">[<a target="_blank" href="https://cs.unc.edu/~anderson/papers/rtas17b.pdf">Paper</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Registration of Pathological Images</b></p>
                <p class="paper">Xiao Yang, Xu Han, Eunbyung Park, Stephen Aylward, Roland Kwitt, Marc Niethammer</p>
                <p class="paper">Simulation an Synthesis in Medical Imaging, <b>MICCAI 2016 Workshop</b></p>
                <p class="paper">[<a target="_blank" href="http://wwwx.cs.unc.edu/~mn/sites/default/files/yang_miccai_2016_tumor.pdf">Paper</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Learning to Decompose for Object Detection and Instance Segmentation</b></p>
                <p class="paper">Eunbyung Park, Alexander C. Berg</p>
                <p class="paper">International Conference on Learning Representations, <b>ICLR 2016 Workshop</b></p>
                <p class="paper">[<a target="_blank" href="http://arxiv.org/abs/1511.06449">Paper</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Combining Multiple Sources of Knowledge in Deep CNNs for Action Recognition</b></p>
                <p class="paper">Eunbyung Park, Xufeng Han, Tamara L. Berg, Alexander C. Berg</p>
                <p class="paper">IEEE Winter Conference on Applications of Computer Vision, <b>WACV 2016</b></p>
                <p class="paper">[<a target="_blank" href="https://www.cs.unc.edu/~eunbyung/papers/wacv2016_combining.pdf">Paper</a>]</p>
                </li>
                <li class="list-group-item">
                <p class="paper"><b>Visual Madlibs: Fill-in-the-blank Image Description and Question Answering</b></p>
                <p class="paper">Licheng Yu, Eunbyung Park, Alexander C. Berg, Tamara L. Berg</p>
                <p class="paper">International Conference on Computer Vision, <b>ICCV 2015</b></p>
                <p class="paper"> <div class="description"> [<a target="_blank" href="https://www.cs.unc.edu/~eunbyung/papers/iccv15_madlibs.pdf">Paper</a>][<a target="_blank" href="http://tamaraberg.com/visualmadlibs/">Project Page</a>][<a target="_blank" href="https://www.cs.unc.edu/~eunbyung/images/iccv15_madlibs.mp4">Spotlight Video</a>][<a target="_blank" href="https://www.cs.unc.edu/~eunbyung/papers/iccv15_madlibs_supp.pdf">Supplementary File</a>] </p>
                </li>

  </div>
</body>
</html>



